# test_trained_model.py
"""
ç‹¬ç«‹æµ‹è¯•è®­ç»ƒå¥½çš„LunarLander DQNæ¨¡å‹
ä¸éœ€è¦é‡æ–°è®­ç»ƒ
"""

import gymnasium as gym
import numpy as np
import tensorflow as tf
from tensorflow import keras
import os

def load_trained_model():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    model_path = './weights/lunar_lander_dqn.h5'
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None
    
    # æ„å»ºç›¸åŒçš„ç½‘ç»œç»“æ„
    model = keras.Sequential([
        keras.layers.Dense(64, activation='relu', input_shape=(8,)),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(4, activation='linear')
    ])
    
    # åŠ è½½æƒé‡
    model.load_weights(model_path)
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
    return model

def test_model(num_episodes=10, render=True):
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print("=" * 60)
    print("ğŸ§ª Testing Trained LunarLander DQN Model")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    model = load_trained_model()
    if model is None:
        return
    
    # åˆ›å»ºç¯å¢ƒ
    render_mode = "human" if render else None
    env = gym.make("LunarLander-v2", render_mode=render_mode)
    
    test_rewards = []
    
    for episode in range(num_episodes):
        state, _ = env.reset()
        episode_reward = 0
        steps = 0
        
        for t in range(1000):
            # é€‰æ‹©æœ€ä¼˜åŠ¨ä½œï¼ˆæ— æ¢ç´¢ï¼‰
            state_tensor = tf.convert_to_tensor(state[None, :], dtype=tf.float32)
            q_values = model(state_tensor, training=False)
            action = np.argmax(q_values[0].numpy())
            
            # æ‰§è¡ŒåŠ¨ä½œ
            next_state, reward, terminated, truncated, _ = env.step(action)
            done = terminated or truncated
            
            # æ›´æ–°çŠ¶æ€å’Œå¥–åŠ±
            state = next_state
            episode_reward += reward
            steps += 1
            
            if done:
                break
        
        test_rewards.append(episode_reward)
        print(f"ğŸ§ª Test Episode {episode:3d} | "
              f"Reward: {episode_reward:7.2f} | "
              f"Steps: {steps:4d}")
    
    env.close()
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“Š FINAL TEST RESULTS")
    print("=" * 60)
    
    if test_rewards:
        avg_reward = np.mean(test_rewards)
        std_reward = np.std(test_rewards)
        max_reward = np.max(test_rewards)
        min_reward = np.min(test_rewards)
        
        # è®¡ç®—æˆåŠŸç‡ï¼ˆ>200ä¸ºæˆåŠŸç€é™†ï¼‰
        success_count = sum(1 for r in test_rewards if r > 200)
        success_rate = (success_count / len(test_rewards)) * 100
        
        print(f"ğŸ“ˆ æµ‹è¯•å›åˆæ•°: {len(test_rewards)}")
        print(f"ğŸ’° å¹³å‡å¥–åŠ±: {avg_reward:.2f}")
        print(f"ğŸ“Š æ ‡å‡†å·®: {std_reward:.2f}")
        print(f"ğŸ† æœ€é«˜å¥–åŠ±: {max_reward:.2f}")
        print(f"ğŸ“‰ æœ€ä½å¥–åŠ±: {min_reward:.2f}")
        print(f"âœ… æˆåŠŸç‡ (>200): {success_rate:.1f}% ({success_count}/{len(test_rewards)})")
        
        # æ€§èƒ½è¯„ä¼°
        if avg_reward > 200:
            print("ğŸ‰ æ€§èƒ½è¯„çº§: ä¼˜ç§€ - æ™ºèƒ½ä½“å·²å­¦ä¼šç¨³å®šç€é™†!")
        elif avg_reward > 100:
            print("ğŸ‘ æ€§èƒ½è¯„çº§: è‰¯å¥½ - æ™ºèƒ½ä½“åŸºæœ¬æŒæ¡ç€é™†")
        elif avg_reward > 0:
            print("ğŸ‘Œ æ€§èƒ½è¯„çº§: åŠæ ¼ - æ™ºèƒ½ä½“å¼€å§‹å­¦ä¹ ")
        else:
            print("âš ï¸  æ€§èƒ½è¯„çº§: éœ€æ”¹è¿› - æ™ºèƒ½ä½“ä»éœ€è®­ç»ƒ")
    
    print("=" * 60)
    return test_rewards

def record_demo():
    """å½•åˆ¶ä¸€ä¸ªæ¼”ç¤ºå›åˆ"""
    print("ğŸ¥ Recording demonstration episode...")
    
    model = load_trained_model()
    if model is None:
        return
    
    # åˆ›å»ºç¯å¢ƒ
    env = gym.make("LunarLander-v2", render_mode="rgb_array")
    state, _ = env.reset()
    
    frames = []
    episode_reward = 0
    
    for t in range(1000):
        # é€‰æ‹©åŠ¨ä½œ
        state_tensor = tf.convert_to_tensor(state[None, :], dtype=tf.float32)
        q_values = model(state_tensor, training=False)
        action = np.argmax(q_values[0].numpy())
        
        # æ‰§è¡ŒåŠ¨ä½œ
        next_state, reward, terminated, truncated, _ = env.step(action)
        done = terminated or truncated
        
        # è®°å½•å¸§ï¼ˆç”¨äºåˆ¶ä½œGIFï¼‰
        frame = env.render()
        frames.append(frame)
        
        state = next_state
        episode_reward += reward
        
        if done:
            break
    
    env.close()
    
    print(f"ğŸ¬ æ¼”ç¤ºå›åˆå½•åˆ¶å®Œæˆ!")
    print(f"ğŸ’° æ¼”ç¤ºå¥–åŠ±: {episode_reward:.2f}")
    print(f"ğŸ“· å½•åˆ¶å¸§æ•°: {len(frames)}")
    
    # å¯ä»¥ä¿å­˜ä¸ºGIFï¼ˆéœ€è¦å®‰è£…imageioï¼‰
    try:
        import imageio
        imageio.mimsave('./lunar_lander_demo.gif', frames, fps=30)
        print("âœ… æ¼”ç¤ºå·²ä¿å­˜ä¸º: ./lunar_lander_demo.gif")
    except:
        print("âš ï¸  æ— æ³•ä¿å­˜GIFï¼Œè¯·å®‰è£…: pip install imageio")

if __name__ == "__main__":
    print("ğŸŒ™ LunarLander-v2 DQN Model Tester")
    print("ğŸ“š Testing pre-trained model without re-training")
    print("=" * 60)
    
    # é€‰æ‹©æµ‹è¯•æ¨¡å¼
    print("é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å¿«é€Ÿæµ‹è¯• (5å›åˆ)")
    print("2. å®Œæ•´æµ‹è¯• (10å›åˆ)")
    print("3. å½•åˆ¶æ¼”ç¤º")
    print("4. æ— æ¸²æŸ“æµ‹è¯•")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
    
    if choice == "1":
        test_model(num_episodes=5, render=True)
    elif choice == "2":
        test_model(num_episodes=10, render=True)
    elif choice == "3":
        record_demo()
    elif choice == "4":
        test_model(num_episodes=10, render=False)
    else:
        print("ä½¿ç”¨é»˜è®¤è®¾ç½®: å¿«é€Ÿæµ‹è¯•")
        test_model(num_episodes=5, render=True)